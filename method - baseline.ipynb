{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import pyclustering\n",
    "from pyclustering.cluster.kmedoids import kmedoids\n",
    "import gower\n",
    "import seaborn as sns\n",
    "import pyclustering\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.kmedoids import kmedoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>delta</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>381.513614</td>\n",
       "      <td>0.229575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>348.888315</td>\n",
       "      <td>0.360779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>313.475708</td>\n",
       "      <td>0.720267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>391.312302</td>\n",
       "      <td>0.623395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>342.378427</td>\n",
       "      <td>0.506764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>366.991464</td>\n",
       "      <td>0.408907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>334.777715</td>\n",
       "      <td>0.751939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>314.411841</td>\n",
       "      <td>0.619102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>234.261070</td>\n",
       "      <td>1.061910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>394.874521</td>\n",
       "      <td>0.563747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha beta       gamma     delta  label\n",
       "0      B    C  381.513614  0.229575      0\n",
       "1      B    E  348.888315  0.360779      0\n",
       "2      B    E  313.475708  0.720267      0\n",
       "3      A    D  391.312302  0.623395      0\n",
       "4      A    D  342.378427  0.506764      1\n",
       "..   ...  ...         ...       ...    ...\n",
       "95     B    E  366.991464  0.408907      0\n",
       "96     A    D  334.777715  0.751939      0\n",
       "97     A    D  314.411841  0.619102      0\n",
       "98     B    E  234.261070  1.061910      0\n",
       "99     B    D  394.874521  0.563747      0\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"artificial_dataset.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define which features are categorical and which are numerical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create lists of categorical and numerical features\n",
    "cat_features = ['alpha','beta']\n",
    "num_features = ['gamma','delta'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-medoids clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function compute the Gower distance matrix\n",
    "# input: NxM feature matrix\n",
    "# output: NxN distance matrix \n",
    "\n",
    "def gower_distance(matrix):\n",
    "    output = gower.gower_matrix(matrix)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function gives a summary of the cluster\n",
    "# input: NxM feature matrix, dictionary with clusters, number of cluster \n",
    "# output: summary of given cluster number \n",
    "\n",
    "def summarize_cluster(matrix,clusters,cluster_number):\n",
    "    c_indices = clusters[cluster_number]\n",
    "    matrix_subset = matrix.loc[c_indices,:]\n",
    "    print('----------------------------------------------------------------------------------------------')\n",
    "    print(\"Summary of cluster: \" , cluster_number)\n",
    "    print('Samples in cluster: ' , len(c_indices))\n",
    "    print('---------------------------------------Features-----------------------------------------------')\n",
    "    for col in matrix_subset.columns:\n",
    "        print(col ,'\\t', matrix_subset[col].tolist())\n",
    "    print('----------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define the feature matrix (X) and the lavel vector (y). We also choose the number of clusters k and initialize the first cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[: , df.columns != 'label']\n",
    "y = df.loc[: , df.columns == 'label']\n",
    "k = 5\n",
    "n = len(X)\n",
    "\n",
    "initial_medoids = np.sort(np.random.choice(n,k))\n",
    "kmedoids_instance = kmedoids(gower_distance(X),initial_medoids,data_type='distance_matrix',iter_max=1000)\n",
    "kmedoids_instance.process()\n",
    "clusters = kmedoids_instance.get_clusters()\n",
    "centers = kmedoids_instance.get_medoids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ML algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-e9bf63b1c235>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column] = le.fit_transform(data[column])\n"
     ]
    }
   ],
   "source": [
    "data = df.loc[: , df.columns != 'label']\n",
    "label = df.loc[: , df.columns == 'label']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for column in cat_features:\n",
    "    le.fit(data[column])\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, np.ravel(label), test_size=0.30, random_state=78) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions train set \t 65.71428571428571\n",
      "correct predictions test set \t 63.33333333333333\n",
      "correct predictions total set \t 65.0\n"
     ]
    }
   ],
   "source": [
    "#train logistic regression model and check performance\n",
    "clf = LogisticRegression(random_state=100).fit(X_train, y_train)\n",
    "clf_predictions_train = clf.predict(X_train)\n",
    "clf_predictions_test = clf.predict(X_test)\n",
    "clf_predictions_total = clf.predict(data)\n",
    "\n",
    "p_correct_train = 1 - (abs(clf_predictions_train-y_train).sum() / len(y_train))\n",
    "p_correct_test = 1 - (abs(clf_predictions_test-y_test).sum() / len(y_test))\n",
    "p_correct_total = 1 - (abs(clf_predictions_total-np.ravel(label)).sum() / len(np.ravel(label)))\n",
    "\n",
    "print('correct predictions train set' ,'\\t', p_correct_train*100)\n",
    "print('correct predictions test set' , '\\t',  p_correct_test*100)\n",
    "print('correct predictions total set' , '\\t', p_correct_total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. XGboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:17:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "correct predictions train set \t 84.28571428571429\n",
      "correct predictions test set \t 56.666666666666664\n",
      "correct predictions total set \t 76.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mieke\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#train XGboost\n",
    "xg_clf = xgb.XGBClassifier(max_depth=5, gamma=1)\n",
    "xg_clf.fit(X_train, y_train)\n",
    "\n",
    "xg_predictions_train = xg_clf.predict(X_train)\n",
    "xg_predictions_test = xg_clf.predict(X_test)\n",
    "xg_predictions_total = xg_clf.predict(data)\n",
    "\n",
    "p_correct_train = 1 - (abs(xg_predictions_train-y_train).sum() / len(y_train))\n",
    "p_correct_test = 1 - (abs(xg_predictions_test-y_test).sum() / len(y_test))\n",
    "p_correct_total = 1 - (abs(xg_predictions_total-np.ravel(label)).sum() / len(np.ravel(label)))\n",
    "\n",
    "print('correct predictions train set' ,'\\t', p_correct_train*100)\n",
    "print('correct predictions test set' , '\\t',  p_correct_test*100)\n",
    "print('correct predictions total set' , '\\t', p_correct_total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machine classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions train set \t 65.71428571428571\n",
      "correct predictions test set \t 63.33333333333333\n",
      "correct predictions total set \t 65.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(X_train,y_train)\n",
    "\n",
    "svm_predictions_train = svm_clf.predict(X_train)\n",
    "svm_predictions_test = svm_clf.predict(X_test)\n",
    "svm_predictions_total = svm_clf.predict(data)\n",
    "\n",
    "p_correct_train = 1 - (abs(svm_predictions_train-y_train).sum() / len(y_train))\n",
    "p_correct_test = 1 - (abs(svm_predictions_test-y_test).sum() / len(y_test))\n",
    "p_correct_total = 1 - (abs(svm_predictions_total-np.ravel(label)).sum() / len(np.ravel(label)))\n",
    "\n",
    "print('correct predictions train set' ,'\\t', p_correct_train*100)\n",
    "print('correct predictions test set' , '\\t',  p_correct_test*100)\n",
    "print('correct predictions total set' , '\\t', p_correct_total*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cluster we will compute the percentage correct predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: array with predicted labels, array with true labels\n",
    "#output: percentage correct predicted labels \n",
    "\n",
    "def correct_predicted(predicted_labels,true_labels):\n",
    "    output = (1 - (abs(predicted_labels-true_labels).sum() / len(true_labels))) * 100\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "Summary of cluster:  0\n",
      "Samples in cluster:  17\n",
      "---------------------------------------Features-----------------------------------------------\n",
      "alpha \t ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n",
      "beta \t ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "gamma \t [316.4427812731012, 438.6389583103979, 363.5354911387662, 258.1767777232494, 401.3809827383549, 377.9564017133732, 286.3695336330434, 398.6828607234717, 387.2588567343811, 309.0108283148952, 369.9955956928401, 285.5834653587883, 355.1922344420338, 368.8696890709799, 261.6543443069412, 331.1820581715405, 394.8745207400268]\n",
      "delta \t [0.389054482289937, 0.4677094006869512, 0.07033947845761684, 0.5116565728780655, 0.8182538768899543, 0.7506398299475989, 0.288842717051486, 0.439229424737304, 0.6637188521557412, 0.71574559680886, 0.7450268891793663, 0.3217983488176098, 0.4215966745821107, 0.4601243411956958, 0.1668653281638692, 0.1269653599334716, 0.5637471750272625]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "Summary of cluster:  1\n",
      "Samples in cluster:  12\n",
      "---------------------------------------Features-----------------------------------------------\n",
      "alpha \t ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "beta \t ['E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E']\n",
      "gamma \t [808.525706420558, 138.2772225977595, 134.3409413551947, 104.6366957768361, 347.6845062681812, 631.5141493802927, 444.8096115901395, 380.2412636647039, 318.4624590885551, 265.9154575446277, 152.8582612065477, 176.1147072739108]\n",
      "delta \t [0.3828827162292031, 0.5816693961840395, 0.7433508653630546, 0.1735124215033929, 0.9443117752643964, 0.5254736981208643, 0.7612533417766565, 0.8562932807091471, 0.4910820188422234, 0.7221066664711886, 0.5628899886326391, 0.6017657769028633]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "Summary of cluster:  2\n",
      "Samples in cluster:  21\n",
      "---------------------------------------Features-----------------------------------------------\n",
      "alpha \t ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "beta \t ['D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D', 'D']\n",
      "gamma \t [391.3123023306014, 342.3784265888951, 251.3569861824076, 411.3977299797951, 383.7718939089774, 573.2821902036188, 316.673952855074, 649.0896972548254, 383.6095495452503, 612.7091733482696, 492.4056529373602, 183.1922596769367, 190.1916695250525, 331.3553923182749, 632.5411618814818, 422.156305688864, 452.7090765976662, 379.2618474986699, 224.9536789427259, 334.7777150563562, 314.4118411845835]\n",
      "delta \t [0.6233952181436982, 0.5067639870286231, 0.5715784235440688, 0.4783427020911818, 0.5118898287647878, 0.6157898612136106, 0.4805996258415492, 0.5844688973895302, 0.8042013693768773, 0.3924589163994266, 0.3214534638413258, 0.4674294906981344, 0.4657755744523576, 0.6484609280479873, 0.4524132185506378, 0.3812856166303151, 0.3799324068207078, 0.5346434598072908, 0.6139877233064299, 0.7519389526493787, 0.6191023483035035]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "Summary of cluster:  3\n",
      "Samples in cluster:  24\n",
      "---------------------------------------Features-----------------------------------------------\n",
      "alpha \t ['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B']\n",
      "beta \t ['C', 'E', 'E', 'E', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'C', 'E', 'E', 'E', 'C', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E']\n",
      "gamma \t [381.5136142977133, 348.8883145991383, 313.4757078268139, 454.2742998601893, 340.7044773040489, 188.4867970304907, 166.7173596883837, 363.7006768602553, 273.8864684456408, 240.5364808598578, 286.5147416081915, 418.7718521976993, 400.3208086957152, 574.9635831570779, 399.4311129477373, 354.5625737140987, 450.058830727256, 307.9855230858705, 257.7826679362893, 292.7332315339563, 478.5485570777807, 361.8206328693563, 366.9914640463521, 234.2610695417152]\n",
      "delta \t [0.2295753583049868, 0.3607789603592759, 0.7202666743177268, 0.9211958453771867, 0.2244159563240348, 0.9590525046539651, -0.09698980421290782, 0.4976194618645681, 0.5130602216430268, 0.2825310299096759, 0.126535192907991, 0.2091669558108125, 0.3826216108186434, 0.6404463562837804, -0.1517881957234372, 0.3845759308259575, -0.06556341591319159, 0.3069744616574661, 0.3513419047241513, 0.9766549747335054, 0.897555568831597, -0.1394244236922014, 0.408906680908582, 1.061909507406722]\n",
      "----------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "Summary of cluster:  4\n",
      "Samples in cluster:  26\n",
      "---------------------------------------Features-----------------------------------------------\n",
      "alpha \t ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "beta \t ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "gamma \t [417.8843433687824, 487.9958658393904, 473.2757094740596, 141.3753593360685, 682.2709306594106, 125.2926910506649, 590.2912539187113, 410.4912266455489, 722.1864634151004, 771.5728647924807, 135.1167461393828, 641.1943122872029, 591.8532149712239, 515.9916227113727, 464.5328152515825, 768.3798759170191, 718.9251290851025, 471.522953137982, 475.2469746732143, 559.4199319077923, 587.670448580118, 645.3667560753809, 448.5020805487322, 674.2996495401112, 273.966006415221, 533.9035724231509]\n",
      "delta \t [0.5334754952168534, 0.3907753981154972, 0.5632970304973614, 0.4021998029902239, 0.6680824443067944, 0.5530721080950376, 0.6181453095138536, 0.8219573358315165, 0.4918089927557653, 0.8636051939237956, 0.6063386632345091, 0.696553821106653, 0.641871420167214, 0.5886564332827056, 0.5926602541417404, 0.7155041510014699, 0.6082015038619555, 1.211593740116776, 0.5380117493628831, 0.4492527904914122, 0.7181676822451857, 0.7580489950437305, 0.5689879734159591, 0.4902503053459084, 0.5285822235372577, 0.5671551039026785]\n",
      "----------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#summarize clusters\n",
    "for i in np.arange(k):\n",
    "    summarize_cluster(X,clusters,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0 \t 70.58823529411764\n",
      "Cluster  1 \t 50.0\n",
      "Cluster  2 \t 57.14285714285714\n",
      "Cluster  3 \t 75.0\n",
      "Cluster  4 \t 65.38461538461539\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(k):\n",
    "    indices = clusters[i]\n",
    "    subset_X = data.loc[indices,:]\n",
    "    subset_y = label.loc[indices,:]\n",
    "    clf_predictions_cluster = clf.predict(subset_X)\n",
    "    print('Cluster ', i , '\\t', correct_predicted(clf_predictions_cluster,np.ravel(subset_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. XGboost classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0 \t 82.35294117647058\n",
      "Cluster  1 \t 91.66666666666666\n",
      "Cluster  2 \t 66.66666666666667\n",
      "Cluster  3 \t 83.33333333333334\n",
      "Cluster  4 \t 65.38461538461539\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(k):\n",
    "    indices = clusters[i]\n",
    "    subset_X = data.loc[indices,:]\n",
    "    subset_y = label.loc[indices,:]\n",
    "    xg_predictions_cluster = xg_clf.predict(subset_X)\n",
    "    print('Cluster ', i , '\\t', correct_predicted(xg_predictions_cluster,np.ravel(subset_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVM classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  0 \t 70.58823529411764\n",
      "Cluster  1 \t 50.0\n",
      "Cluster  2 \t 57.14285714285714\n",
      "Cluster  3 \t 75.0\n",
      "Cluster  4 \t 65.38461538461539\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(k):\n",
    "    indices = clusters[i]\n",
    "    subset_X = data.loc[indices,:]\n",
    "    subset_y = label.loc[indices,:]\n",
    "    svm_predictions_cluster = svm_clf.predict(subset_X)\n",
    "    print('Cluster ', i , '\\t', correct_predicted(svm_predictions_cluster,np.ravel(subset_y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
